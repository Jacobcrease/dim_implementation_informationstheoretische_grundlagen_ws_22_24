{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What this is about\n",
    "The basic idea of Deep Infomax (DIM) is to have a setup that allows you to combine multiple training goals.\n",
    "This is combined with the idea of maximizing MI in order to do unsupervised learning as effectively as possible.\n",
    "\n",
    "I have tried to recreate this approach in **Tensorflow**.\n",
    "\n",
    "In doing so, I ran into some issues that made it very difficult to show my results within an ipynb file.\n",
    "Therefore I have 4 different files.\n",
    "\n",
    "### How the Files are structured\n",
    "File 0_ deals with training an encoder using the approach of DIM.\n",
    "\n",
    "To evaluate if the results can be used, I built several classifiers that try to match the images of the mnist dataset to the correct numbers based on the features learned from the encoder.\n",
    "In file 1_ I build a simple classifier without my encoder.\n",
    "I got the code for it from: [Tensorflow: writing training loop tutorial](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)\n",
    "In file 2_ I have adapted the code to run the images through the encoder before passing them through the same network.\n",
    "\n",
    "In file 3_ I present then briefly the data and refer to it.\n",
    "\n",
    "### To run this on your own\n",
    "I coded this on a Windows 10 machine with python **3.10.1**\n",
    "You can install the requirements by executing `pip install -r ./requirements.txt`\n",
    "To build multiple encoders, you need to re-run every cell, as I'm using `@tf.function` and was not able to find out how to reuse the function.\n",
    "\n",
    "### About Sources:\n",
    "I needed to learn tensorflow first, I used these tutorial very heavily in the beginning, and started from scratch later.\n",
    "- [Install Tensorflow](https://www.tensorflow.org/install/pip)\n",
    "- [Tensorflow: writing training loop tutorial](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)\n",
    "- [Tensorflow: dcgan tutorial](https://www.tensorflow.org/tutorials/generative/dcgan)\n",
    "- [Tensorflow: functional api tutorial](https://www.tensorflow.org/guide/keras/functional)\n",
    "- [Tensorflow: save and load models](https://www.tensorflow.org/guide/keras/save_and_serialize)\n",
    "- [Tensorflow docs: KLDivergence](https://www.tensorflow.org/api_docs/python/tf/keras/losses/KLDivergence)\n",
    "- [Tensorflow docs: Math](https://www.tensorflow.org/api_docs/python/tf/math)\n",
    "\n",
    "Also I used the Paper as a Resource and some follow up works\n",
    "- [Learning deep representations by mutual information estimation and maximization](https://arxiv.org/abs/1808.06670)\n",
    "- [Deep InfoMax: Learning good representations through mutual information maximization](https://www.microsoft.com/en-us/research/blog/deep-infomax-learning-good-representations-through-mutual-information-maximization/)\n",
    "- [Jehill Parikh: Deep InfoMax Tensorflow-Keras Implementation](https://jehillparikh.medium.com/deep-info-max-tensorflow-keras-implementation-b1faeffb0260)\n",
    "\n",
    "I marked every cell where copied code over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Workaround for Pylance\n",
    "keras = tf.keras\n",
    "from keras import layers, models, losses\n",
    "\n",
    "kl = tf.keras.losses.KLDivergence()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training data\n",
    "I used the mnist dataset. Like mentioned in [Tensorflow: writing training loop tutorial](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) I reserved some samples for validation. Which I'm doing in 1_ and 2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\"float32\")\n",
    "\n",
    "train_images = train_images[:-10000]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIM seperates it's training into 3 Tasks:\n",
    "- Global Dim task\n",
    "- Local Dim task\n",
    "- Prior-Matching\n",
    "\n",
    "For each task it needs it's own discriminator.\n",
    "\n",
    "So I need 4 Models:\n",
    "1. Encoder I want to train\n",
    "2. Global-Discriminator\n",
    "3. Local-Discriminator\n",
    "4. Prior-Discriminator\n",
    "\n",
    "The Encoder Needs to extract the local features of different Kernals into a MxM Feature Map\n",
    "In the examples provided within paper they use 4 convolutional layers, the last one being the final local feature map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Factory Function returns the Encoder.\n",
    "\n",
    "Model Output:\n",
    "conv4: The local MxM feature map (M=5 in this example)\n",
    "fc: Global Feature Vector\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def make_encoder_model():\n",
    "    encoder_input = layers.Input(shape=(28, 28, 1), name=\"image\")\n",
    "\n",
    "    conv_1 = layers.Conv2D(filters=32, kernel_size=6, strides=5, activation=\"relu\")(\n",
    "        encoder_input\n",
    "    )\n",
    "    conv_2 = layers.Conv2D(filters=64, kernel_size=1, strides=1, activation=\"relu\")(\n",
    "        conv_1\n",
    "    )\n",
    "    conv_3 = layers.Conv2D(filters=128, kernel_size=1, strides=1, activation=\"relu\")(\n",
    "        conv_2\n",
    "    )\n",
    "    conv_4 = layers.Conv2D(filters=256, kernel_size=1, strides=1, activation=\"relu\")(\n",
    "        conv_3\n",
    "    )\n",
    "\n",
    "    fc = layers.Flatten()(conv_4)\n",
    "    fc = layers.Dense(256, activation=\"relu\")(fc)\n",
    "    fc = layers.Dense(32)(fc)\n",
    "\n",
    "    return models.Model(inputs=encoder_input, outputs=[conv_4, fc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Factory Function returns a discriminator for the global dim task.\n",
    "\n",
    "Task of this discriminator is to give a high score if the inputs belong together\n",
    "\n",
    "Does that by bringing both together in one 1D-Layer and densing it down to a single float\n",
    "\n",
    "Model Output:\n",
    "Score (float)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def make_global_discriminator_model():\n",
    "    conv_4 = layers.Input(shape=(5, 5, 256), name=\"local_feature_map\")\n",
    "    fc = layers.Input(shape=(32), name=\"global_feature_vector\")\n",
    "\n",
    "    flattend_map = layers.Flatten()(conv_4)\n",
    "    combined = layers.Concatenate()([flattend_map, fc])\n",
    "\n",
    "    densed = layers.Dense(128, activation=\"relu\")(combined)\n",
    "    densed = layers.Dense(16, activation=\"relu\")(densed)\n",
    "\n",
    "    score = layers.Dense(1)(densed)\n",
    "    return models.Model(inputs=[conv_4, fc], outputs=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Factory Function returns a discriminator for the local dim task.\n",
    "\n",
    "Task of this discriminator is to give a high score for each local feature vector\n",
    "if the global vector belongs to the same source\n",
    "\n",
    "This is done by building a feature map of same dimensions like the conv_4 of the encoder.\n",
    "After that both maps can be concatinated.\n",
    "\n",
    "Also I renamed the input of the conv_4 here, as I'm using conv and wanted to avoid confusion here\n",
    "\n",
    "Appends the global vector to each of the MxM local vectors\n",
    "\n",
    "Model Output:\n",
    "Map out of MxM scores (floats)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def make_local_discriminator_model():\n",
    "    f_map = layers.Input(shape=(5, 5, 256), name=\"local_feature_map\")\n",
    "    fc = layers.Input(shape=(32), name=\"global_feature_vector\")\n",
    "\n",
    "    # tested if it works in that way\n",
    "    # it does!\n",
    "    score = layers.RepeatVector(25)(fc)\n",
    "    resh = layers.Reshape((5, 5, 32), input_shape=(25, 32))(score)\n",
    "\n",
    "    combined_map = layers.Concatenate(axis=3)([f_map, resh])\n",
    "\n",
    "    # again 4 convolutional networks to boil it down to a usable size\n",
    "    conv_1 = layers.Conv2D(filters=128, kernel_size=1, strides=1, activation=\"relu\")(\n",
    "        combined_map\n",
    "    )\n",
    "    conv_2 = layers.Conv2D(filters=64, kernel_size=1, strides=1, activation=\"relu\")(\n",
    "        conv_1\n",
    "    )\n",
    "    conv_3 = layers.Conv2D(filters=32, kernel_size=1, strides=1, activation=\"relu\")(\n",
    "        conv_2\n",
    "    )\n",
    "    conv_4 = layers.Conv2D(filters=16, kernel_size=1, strides=1, activation=\"relu\")(\n",
    "        conv_3\n",
    "    )\n",
    "\n",
    "    score_map = layers.Conv2D(filters=1, kernel_size=1, strides=1)(conv_4)\n",
    "    return models.Model(inputs=[f_map, fc], outputs=score_map)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the prior matching I used the implementation of [Jehill Parikh](https://jehillparikh.medium.com/deep-info-max-tensorflow-keras-implementation-b1faeffb0260)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Factory Function returns a discriminator for the prior matching part.\n",
    "Task of this is to predict if the global feature input belongs to an encoded prior\n",
    "High-Score = encoded prior\n",
    "\n",
    "Model Output:\n",
    "Score (float)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def make_prior_matching_discriminator_model():\n",
    "    fc = layers.Input(shape=(32), name=\"global_feature_vector\")\n",
    "    p1 = layers.Dense(32, use_bias=False)(fc)\n",
    "    p1 = layers.BatchNormalization()(p1)\n",
    "    p1 = layers.Activation(\"relu\")(p1)\n",
    "    p1 = layers.Dense(200, use_bias=False)(p1)\n",
    "    p1 = layers.BatchNormalization()(p1)\n",
    "    p1 = layers.Activation(\"relu\")(p1)\n",
    "    p1 = layers.Dense(1)(p1)\n",
    "    return models.Model(inputs=fc, outputs=p1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part I defined the loss functions. The one for the encoder is especially important for DIM, as it should be easy to swap MI estimators to provide flexibility.\n",
    "For the MI estimator, it is important that a high score defines a high MI for the encoder.\n",
    "\n",
    "While the discriminators need only be simple discriminators.\n",
    "The authors of the paper describe that they used a dcgan implementation for their implementation.\n",
    "So I also just used a sample implementation of [Tensorflow: dcgan tutorial](https://www.tensorflow.org/tutorials/generative/dcgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "# from a tensorflow dcgan tutorial\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the JSD based MI estimator mentioned by the authors. As it seems to provide stable results with few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "can never get positive, higher value means estimated MI is higher\n",
    "If goal is to maximize MI, this needs to be negated for loss functions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def tensor_jsd(joint_scored, marginals_scored):\n",
    "    neg_joint_softplus = tf.math.negative(\n",
    "        tf.math.softplus(tf.math.negative(joint_scored))\n",
    "    )\n",
    "    marginals_softplus = tf.math.softplus(marginals_scored)\n",
    "    return tf.subtract(neg_joint_softplus, marginals_softplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The encoder has different goals for each DIM task\n",
    "It tries to fool the global and local discriminators, by maximizing the MI\n",
    "So it uses the scored from the descriminators and uses a MI estimator.\n",
    "The authors show in the paper that it's possible to use different Estimators.\n",
    "Only thing important is, that a higher score means higher MI\n",
    "\n",
    "We want to be able give it some weights, so that we prioritize one task over another\n",
    "\n",
    "While we want to maximize the global and local score -> meaning minimizing the loss\n",
    "As they become minimal for our wanted behaviour\n",
    "\n",
    "For the prior_matching on the other hand, we just need to calculate the deviation between the prior and the real results\n",
    "I use the KL divergence for that.\n",
    "Anyhow, I need to do some calculations, to make sure the tensorflow implementation provides stable results.\n",
    "If the input would be negative, the divergence would not work, so watch out.\n",
    "Also, I'm only interested in the absolute diviation.\n",
    "And a higher diviation means the model is less accurate, meaning it indicates a higher loss\n",
    "\n",
    "Assuming that all scores are always negative (see JSD implementation)\n",
    "global and local higher MI -> less loss\n",
    "higher KL divergence with both p scores -> more loss\n",
    "Wanna sum and normalise l_score to same dimension like g_score\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_encoder_loss(\n",
    "    g_weight,\n",
    "    g_pos_scored,\n",
    "    g_neg_scored,\n",
    "    l_weight,\n",
    "    l_pos_scored,\n",
    "    l_neg_scored,\n",
    "    p_weight,\n",
    "    p_pos_scored,\n",
    "    p_neg_scored,\n",
    "):\n",
    "    global_loss = tensor_jsd(g_pos_scored, g_neg_scored) * g_weight\n",
    "\n",
    "    local_reduced = tf.math.reduce_sum(tensor_jsd(l_pos_scored, l_neg_scored), axis=1)\n",
    "    local_reduced = tf.math.reduce_sum(local_reduced, axis=1)\n",
    "    local_devided = tf.math.divide(local_reduced, tf.constant([25.0]))\n",
    "    local_loss = local_devided * l_weight\n",
    "\n",
    "    prior_shape_orientation = local_loss.shape\n",
    "\n",
    "    prior_pos_match_dimension = tf.repeat(\n",
    "        p_pos_scored, prior_shape_orientation[0], axis=0\n",
    "    )\n",
    "    prior_pos_match_dimension = tf.reshape(\n",
    "        prior_pos_match_dimension, prior_shape_orientation\n",
    "    )\n",
    "    prior_pos_abs = tf.math.abs(prior_pos_match_dimension)\n",
    "    prior_neg_match_dimension = tf.reshape(p_neg_scored, prior_shape_orientation)\n",
    "    prior_neg_abs = tf.math.abs(prior_neg_match_dimension)\n",
    "\n",
    "    divergence = tf.math.abs(kl(prior_pos_abs, prior_neg_abs))\n",
    "    prior_loss = tf.ones_like(local_loss) * divergence * p_weight\n",
    "    return tf.negative(global_loss + local_loss) + prior_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helper function is to get negative samples.\n",
    "A sample is a combination of a local feature map and a global feature vector\n",
    "The outputs of the encoder are the positive samples.\n",
    "To get a negative sample, I need to bring together a global feature vector and a feature map from different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset_tensor_by_one(tensor):\n",
    "    \"\"\"Does not change the input\"\"\"\n",
    "    slice = tensor[:1]\n",
    "    slice2 = tensor[1:]\n",
    "    concat = tf.concat([slice2, slice], axis=0)\n",
    "    return concat\n",
    "\n",
    "\n",
    "def create_negative_samples(real_features):\n",
    "    \"\"\"\n",
    "    Return a pair where the global feature vector\n",
    "    is not the one that belongs to the feature map\n",
    "    \"\"\"\n",
    "    [convs, fcs] = real_features\n",
    "    fake_convs = offset_tensor_by_one(convs)\n",
    "    return [fake_convs, fcs]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training\n",
    "Each task has its own goal - but each decoder receives the same encoded sources.\n",
    "Prioritization of tasks is done by specifying weights.\n",
    "These are used by the encoder_loss function.\n",
    "\n",
    "It would be easily possible to adapt each step here, and to add goals or even altering how them.\n",
    "But for that also the encoder_loss function must be adapted.\n",
    "\n",
    "Here a scetch of the train step:\n",
    "\n",
    "![DIM Train Step Sketch](./DIM_task_v3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wanna be able to train multiple models with different setting, that's why I'm defining all of these here\n",
    "encoder = make_encoder_model()\n",
    "encoder_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "global_discriminator = make_global_discriminator_model()\n",
    "global_discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "local_discriminator = make_local_discriminator_model()\n",
    "local_discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "prior_discriminator = make_prior_matching_discriminator_model()\n",
    "prior_discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, prior_image, global_weight, local_weight, prior_weight):\n",
    "    # Doing training and calculating loss\n",
    "    with tf.GradientTape() as enc_tape:\n",
    "        positive_samples = encoder(images, training=True)\n",
    "        negative_samples = create_negative_samples(positive_samples)\n",
    "        prior_sampled = encoder(prior_image, training=True)\n",
    "\n",
    "        # this is the global DIM task\n",
    "        with tf.GradientTape() as global_discriminator_tape:\n",
    "            global_real_output = global_discriminator(positive_samples, training=True)\n",
    "            global_fake_output = global_discriminator(negative_samples, training=True)\n",
    "            global_loss = discriminator_loss(global_real_output, global_fake_output)\n",
    "\n",
    "        # this is the local DIM task\n",
    "        with tf.GradientTape() as local_discriminator_tape:\n",
    "            local_real_output = local_discriminator(positive_samples, training=True)\n",
    "            local_fake_output = local_discriminator(negative_samples, training=True)\n",
    "            local_loss = discriminator_loss(local_real_output, local_fake_output)\n",
    "\n",
    "        # this is the prior matching task\n",
    "        with tf.GradientTape() as prior_discriminator_tape:\n",
    "            prior_real_output = prior_discriminator(prior_sampled[1], training=True)\n",
    "            prior_fake_output = prior_discriminator(positive_samples[1], training=True)\n",
    "            prior_loss = discriminator_loss(prior_real_output, prior_fake_output)\n",
    "\n",
    "        enc_loss = get_encoder_loss(\n",
    "            global_weight,\n",
    "            global_real_output,\n",
    "            global_fake_output,\n",
    "            local_weight,\n",
    "            local_real_output,\n",
    "            local_fake_output,\n",
    "            prior_weight,\n",
    "            prior_real_output,\n",
    "            prior_fake_output,\n",
    "        )\n",
    "\n",
    "    # calculating and applying gradients\n",
    "    gradients_of_encoder = enc_tape.gradient(enc_loss, encoder.trainable_variables)\n",
    "    gradients_of_global = global_discriminator_tape.gradient(\n",
    "        global_loss, global_discriminator.trainable_variables\n",
    "    )\n",
    "    gradients_of_local = local_discriminator_tape.gradient(\n",
    "        local_loss, local_discriminator.trainable_variables\n",
    "    )\n",
    "    gradients_of_prior = prior_discriminator_tape.gradient(\n",
    "        prior_loss, prior_discriminator.trainable_variables\n",
    "    )\n",
    "\n",
    "    encoder_optimizer.apply_gradients(\n",
    "        zip(gradients_of_encoder, encoder.trainable_variables)\n",
    "    )\n",
    "    global_discriminator_optimizer.apply_gradients(\n",
    "        zip(gradients_of_global, global_discriminator.trainable_variables)\n",
    "    )\n",
    "    local_discriminator_optimizer.apply_gradients(\n",
    "        zip(gradients_of_local, local_discriminator.trainable_variables)\n",
    "    )\n",
    "    prior_discriminator_optimizer.apply_gradients(\n",
    "        zip(gradients_of_prior, prior_discriminator.trainable_variables)\n",
    "    )\n",
    "    return tf.math.reduce_mean(enc_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating multiple encoders\n",
    "\n",
    "The training step is held flexible, with this I was able to create multiple models.\n",
    "they are saved with their wheights in name, so it's easier to differentiate them.\n",
    "Sadly it's not easily possible to run the training with different encoders within one run because I used `@tf.function`\n",
    "\n",
    "So the approach to run it multiple times is to wait until the first is finished, then changing the wheights, and running all cells again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    global_weight,\n",
    "    local_weight,\n",
    "    prior_weight,\n",
    "    prior_image,\n",
    "    train_images,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Iterate over the batches of the dataset.\n",
    "        for step, (image_batch) in enumerate(train_dataset):\n",
    "            enc_loss_average = train_step(\n",
    "                global_weight=global_weight,\n",
    "                local_weight=local_weight,\n",
    "                prior_weight=prior_weight,\n",
    "                images=image_batch,\n",
    "                prior_image=prior_image,\n",
    "            )\n",
    "\n",
    "            # Log every 200 batches.\n",
    "            if step % 200 == 0:\n",
    "                print(\n",
    "                    \"Training loss (for one batch) at step {}: {}\".format(\n",
    "                        step, float(enc_loss_average)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(\"------------------------------------\")\n",
    "        print(\"End of epoch:{}\".format(epoch))\n",
    "        print(\"Time taken: {}s\".format(time.time() - start_time))\n",
    "        print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_prefix = \"./models/dim_encoder-\"\n",
    "saved_models_pathes = []\n",
    "\n",
    "\n",
    "def save_model(g_weight, l_weight, p_weight):\n",
    "    model_name = \"g{}-l{}-p{}\".format(g_weight, l_weight, p_weight).replace(\".\", \"_\")\n",
    "    rel_path = path_prefix + model_name\n",
    "    encoder.compile()\n",
    "    encoder.save(rel_path)\n",
    "    print(\"done saved as {}\".format(rel_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_image = tf.ones_like(train_images[0:1])\n",
    "prior_image = tf.math.divide(prior_image, tf.constant([28.0 * 28.0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I train multiple encoders, to get a better understanding in the influence of the different tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "global_dim = g=1, l=0, p=1\n",
    "local_dim = l=1, p=0.1\n",
    "mixed_dim = g=0.6, l=0.4, p=0\n",
    "complete_dim = g=0.6, l=0.4, p=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 1.8513067960739136\n"
     ]
    }
   ],
   "source": [
    "g = 1.0\n",
    "l = 0.0\n",
    "p = 1.0\n",
    "\n",
    "\"\"\"\n",
    "For oprimizations I enabled tf.function for the train step, but because of that, it's not possible to train everything at one\n",
    "So I build the dims one by one, store them and evaluate in another file\n",
    "\"\"\"\n",
    "train(\n",
    "    global_weight=g,\n",
    "    local_weight=l,\n",
    "    prior_weight=p,\n",
    "    prior_image=prior_image,\n",
    "    train_images=train_images,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/dim_encoder-g1_0-l0_0-p1_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/dim_encoder-g1_0-l0_0-p1_0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done saved as ./models/dim_encoder-g1_0-l0_0-p1_0\n"
     ]
    }
   ],
   "source": [
    "save_model(g, l, p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "965c3a2c1d6a903b17a4e58d1a3927382c062c874803c54957326389b3e13b48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
